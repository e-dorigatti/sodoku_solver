{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import (Conv2D, MaxPooling2D, Dense, Flatten,\n",
    "                          GlobalAveragePooling2D, BatchNormalization,\n",
    "                          Dropout, GaussianNoise, AveragePooling2D)\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.regularizers import l2\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_onehot(idx, size):\n",
    "    res = [0] * size\n",
    "    res[idx] = 1\n",
    "    return res\n",
    "\n",
    "\n",
    "labels_fname = './labels.json'\n",
    "with open(labels_fname) as f:\n",
    "    fname_to_label = {\n",
    "        row['fname']: to_onehot(row['label'] or 0, size=10)\n",
    "        for row in list(map(json.loads, f))\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 567 digits\n"
     ]
    }
   ],
   "source": [
    "digits_dir = './digits/'\n",
    "\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "fnames = os.listdir(digits_dir)\n",
    "np.random.shuffle(fnames)\n",
    "for fname in fnames:\n",
    "    images.append(cv2.imread(digits_dir + fname, cv2.IMREAD_GRAYSCALE))\n",
    "    labels.append(fname_to_label[fname])\n",
    "\n",
    "print('Loaded %d digits' % len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(x.shape[0] for x in images), max(x.shape[1] for x in images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (567, 28, 28, 1) - Labels shape: (567, 10)\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(img):\n",
    "    width, height = img.shape\n",
    "    margin_x = int((28 - width) / 2)\n",
    "    margin_y = int((28 - height) / 2)\n",
    "    \n",
    "    res = np.zeros((28, 28, 1))\n",
    "    res[margin_x:margin_x+width, margin_y:margin_y+height, 0] = img\n",
    "    \n",
    "    res = (res - res.mean()) / res.std()\n",
    "    \n",
    "    return res\n",
    "\n",
    "\n",
    "X_all = np.array(list(map(preprocess_image, images)))\n",
    "y_all = np.array(labels)\n",
    "\n",
    "print('Data shape: %s - Labels shape: %s' % (X_all.shape, y_all.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check class (im)balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([122,  53,  45,  47,  51,  48,  45,  55,  55,  46])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only keep a random subset of no-digit images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([52, 53, 45, 47, 51, 48, 45, 55, 55, 46])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = (y_all[:, 0] == 0) | (np.random.random(len(y_all)) < 0.4)\n",
    "X_all, y_all = X_all[mask], y_all[mask]\n",
    "y_all.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next two cells are a temporary fix since apparently I have two versions of OpenMP installed, and the kernel dies when calling model.fit after using the ImageDataGenerator. Therefore, generate the augmented dataset and save it to a file, then restart the kernel. The next time the cell is executed, the dataset will be loaded from the file without creating the ImageDataGenerator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded from augmented.mat\n"
     ]
    }
   ],
   "source": [
    "augmented_fname = 'augmented.mat'\n",
    "if os.path.exists(augmented_fname):\n",
    "    with open(augmented_fname, 'rb') as f:\n",
    "        X_train, y_train = pickle.load(f)\n",
    "    print('loaded from', augmented_fname)\n",
    "else:\n",
    "    idg = ImageDataGenerator(\n",
    "        samplewise_center=True,\n",
    "        samplewise_std_normalization=True,\n",
    "        rotation_range=10,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "    )\n",
    "\n",
    "    idg.fit(X_all)\n",
    "\n",
    "    example = next(idg.flow(X_all, batch_size=24))\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for i, img in enumerate(example):\n",
    "        # every sample is normalized to have zero mean\n",
    "        img[img > 0] = 1\n",
    "        img[img < 0] = 0\n",
    "\n",
    "        plt.subplot(4, 6, i + 1)\n",
    "        plt.imshow(img[:, :, 0])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    augmented_dataset_x = []\n",
    "    augmented_dataset_y = []\n",
    "    for batch_x, batch_y in idg.flow(X_all, y_all, batch_size=24):\n",
    "        augmented_dataset_x.extend(batch_x)\n",
    "        augmented_dataset_y.extend(batch_y)\n",
    "        if len(augmented_dataset_x) > 10000:\n",
    "            break\n",
    "\n",
    "    X_train, y_train = np.array(augmented_dataset_x), np.array(augmented_dataset_y)\n",
    "    X_train.shape, y_train.shape\n",
    "    \n",
    "    with open(augmented_fname, 'wb') as f:\n",
    "        pickle.dump((X_train, y_train), f)\n",
    "    \n",
    "    print('dumped to %s, please restart the kernel' % augmented_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 883, 1089,  925,  968, 1052,  978,  922, 1129, 1133,  945])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gaussian_noise_1 (GaussianNo (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 8)         80        \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 8)         32        \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 8)         584       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 8)         32        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 8)         32        \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 16)        1168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 14, 14, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 14, 14, 16)        64        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 7, 7, 16)          64        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 7, 7, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 7, 7, 32)          4640      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 7, 7, 32)          9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 7, 7, 32)          128       \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 18,914\n",
      "Trainable params: 18,642\n",
      "Non-trainable params: 272\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "l2_strength = 0.0001\n",
    "conv_kwargs = {\n",
    "    'kernel_regularizer': l2(l2_strength),\n",
    "    'activation': 'relu',\n",
    "    'padding': 'same',\n",
    "}\n",
    "\n",
    "model = Sequential([\n",
    "    GaussianNoise(0.025, input_shape=X_all[0].shape),\n",
    "    Conv2D(8, (3, 3), input_shape=X_all[0].shape, **conv_kwargs), BatchNormalization(),\n",
    "    Conv2D(8, (3, 3), **conv_kwargs), BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)), BatchNormalization(),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(16, (3, 3), **conv_kwargs), BatchNormalization(),\n",
    "    Conv2D(16, (3, 3), **conv_kwargs), BatchNormalization(),\n",
    "    MaxPooling2D((2, 2)), BatchNormalization(),\n",
    "    Dropout(0.25),\n",
    "    Conv2D(32, (3, 3), **conv_kwargs), BatchNormalization(),\n",
    "    Conv2D(32, (3, 3), **conv_kwargs), BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dense(10, activation='softmax', kernel_regularizer=l2(l2_strength))\n",
    "])\n",
    "\n",
    "model.compile('adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10024 samples, validate on 497 samples\n",
      "Epoch 1/10\n",
      "10024/10024 [==============================] - 15s 1ms/step - loss: 1.5870 - acc: 0.4661 - val_loss: 0.6926 - val_acc: 0.7807\n",
      "Epoch 2/10\n",
      "10024/10024 [==============================] - 10s 1ms/step - loss: 0.6316 - acc: 0.8274 - val_loss: 0.2161 - val_acc: 0.9497\n",
      "Epoch 3/10\n",
      "10024/10024 [==============================] - 10s 989us/step - loss: 0.3367 - acc: 0.9108 - val_loss: 0.1281 - val_acc: 0.9738\n",
      "Epoch 4/10\n",
      "10024/10024 [==============================] - 10s 1ms/step - loss: 0.2276 - acc: 0.9399 - val_loss: 0.0903 - val_acc: 0.9799\n",
      "Epoch 5/10\n",
      "10024/10024 [==============================] - 10s 1ms/step - loss: 0.1811 - acc: 0.9530 - val_loss: 0.0781 - val_acc: 0.9799\n",
      "Epoch 6/10\n",
      "10024/10024 [==============================] - 12s 1ms/step - loss: 0.1513 - acc: 0.9591 - val_loss: 0.0723 - val_acc: 0.9879\n",
      "Epoch 7/10\n",
      "10024/10024 [==============================] - 10s 972us/step - loss: 0.1317 - acc: 0.9653 - val_loss: 0.0640 - val_acc: 0.9879\n",
      "Epoch 8/10\n",
      "10024/10024 [==============================] - 10s 970us/step - loss: 0.1140 - acc: 0.9707 - val_loss: 0.0588 - val_acc: 0.9899\n",
      "Epoch 9/10\n",
      "10024/10024 [==============================] - 10s 1ms/step - loss: 0.0965 - acc: 0.9784 - val_loss: 0.0623 - val_acc: 0.9859\n",
      "Epoch 10/10\n",
      "10024/10024 [==============================] - 11s 1ms/step - loss: 0.0987 - acc: 0.9751 - val_loss: 0.0716 - val_acc: 0.9859\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    validation_data=(X_all, y_all),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(X_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 1., 53.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0., 45.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 3.,  0.,  0., 47.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0., 51.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0., 48.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0., 45.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0., 55.,  0.,  0.],\n",
       "       [ 3.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 55.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., 46.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_cls = np.argmax(preds, axis=1)\n",
    "true_cls = np.argmax(y_all, axis=1)\n",
    "\n",
    "confusion = np.zeros((10, 10))\n",
    "for p, t in zip(pred_cls, true_cls):\n",
    "    confusion[p, t] += 1\n",
    "    \n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitPredictor:\n",
    "    def __init__(self, model_fname='model.h5'):\n",
    "        self.model = load_model(model_fname)\n",
    "    \n",
    "    def predict_digits(self, images):\n",
    "        ''' being trained for sodoku, this does not predict zeros, and can\n",
    "            tell if the image is not a digit\n",
    "        '''\n",
    "        preds = self.model.predict(np.array(list(map(preprocess_image, images))))\n",
    "        preds_cls = np.argmax(preds, axis=1)\n",
    "        return [\n",
    "            c if c > 0 else None\n",
    "            for c in preds_cls\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = DigitPredictor().predict_digits(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
